{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "12_nlp_dive.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WittmannF/course-v4/blob/master/nbs/12_nlp_dive_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a8G1kixZ5X8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5bcf1e79-7c58-4042-d9c5-3c644a858a37"
      },
      "source": [
        "# Let's first download a utility file for setting up Google Colab\n",
        "!wget https://raw.githubusercontent.com/WittmannF/course-v4/master/utils/colab_utils.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-06 14:34:29--  https://raw.githubusercontent.com/WittmannF/course-v4/master/utils/colab_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1214 (1.2K) [text/plain]\n",
            "Saving to: ‘colab_utils.py’\n",
            "\n",
            "\rcolab_utils.py        0%[                    ]       0  --.-KB/s               \rcolab_utils.py      100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-06 14:34:30 (55.2 MB/s) - ‘colab_utils.py’ saved [1214/1214]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqqYOWxwZ5TV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "afaf108b-cba4-46dd-e94e-6fc0e2481575"
      },
      "source": [
        "from colab_utils import setup_fastai_colab\n",
        "setup_fastai_colab()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    NOTE: For debugging and visualizing stdout, please run:\n",
            "    from colab_utils import *\n",
            "    !{REQUIREMENTS_PIP}\n",
            "    !{GIT_CLONE_REPOSITORY}\n",
            "    %cd {FASTAI_NB_PATH}\n",
            "\n",
            "Installing requirements...\n",
            "Done!\n",
            "Cloning FastAI Repository...\n",
            "Done!\n",
            "Opening folder course-v4/nbs/ with nbs and utils files...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnIs7EcoZhWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hide\n",
        "from utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyv2mCDsZhWQ",
        "colab_type": "text"
      },
      "source": [
        "# A language model from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD1vmRmcZhWR",
        "colab_type": "text"
      },
      "source": [
        "## The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wh_oR9UZhWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "59313ffa-df3f-47ce-a8a1-a0d392111a6d"
      },
      "source": [
        "from fastai2.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBM8hiKJZhWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hide\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7UVCPUnZhWb",
        "colab_type": "code",
        "outputId": "4c617369-4257-4836-d805-c2e136b4d027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('train.txt'),Path('valid.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwGLWLcSZhWh",
        "colab_type": "code",
        "outputId": "e40e9e6f-d37d-4f42-92c1-eafee2830458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "lines"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1s66F07ZhWl",
        "colab_type": "code",
        "outputId": "2026e6fc-f324-434f-dcde-18cd01f34d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = ' . '.join([l.strip() for l in lines])\n",
        "text[:100]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymRXeS37ZhWu",
        "colab_type": "code",
        "outputId": "37e46770-3a22-4edd-998b-c6112b3f3c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnIwW-yQZhW2",
        "colab_type": "code",
        "outputId": "5e30deef-9fbe-40b9-d601-3d4b4c69c291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = L(*tokens).unique()\n",
        "vocab"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmj5Sc1tZhW7",
        "colab_type": "code",
        "outputId": "5247eecb-4095-473b-bd30-fdda0fe4a765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "nums = L(word2idx[i] for i in tokens)\n",
        "nums"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03zPUtRDZhXA",
        "colab_type": "text"
      },
      "source": [
        "## Our first language model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgpvzwwRZhXB",
        "colab_type": "code",
        "outputId": "f8b6f1dc-772d-44b4-9793-a6a0eb8f874a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "L((tokens[i:i+3], tokens[i+3]) for i in range(0,len(tokens)-4,3))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hcdRWWtZhXI",
        "colab_type": "code",
        "outputId": "ea308271-90dc-4650-e1c8-cae98a5fc41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3))\n",
        "seqs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ago1TkS_ZhXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cH7Tm7vZhXY",
        "colab_type": "text"
      },
      "source": [
        "### Our language model in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4PZSegwZhXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel1(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.h_h(self.i_h(x[:,0])))\n",
        "        h = h + self.i_h(x[:,1])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,2])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teMlYguZZhXb",
        "colab_type": "code",
        "outputId": "dbcd5c97-5119-4bb7-ebf2-4186988395bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.824297</td>\n",
              "      <td>1.970941</td>\n",
              "      <td>0.467554</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.386973</td>\n",
              "      <td>1.823242</td>\n",
              "      <td>0.467554</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.417556</td>\n",
              "      <td>1.654497</td>\n",
              "      <td>0.494414</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.376440</td>\n",
              "      <td>1.650849</td>\n",
              "      <td>0.494414</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y0yM-_JZhXf",
        "colab_type": "code",
        "outputId": "8a2cf9fd-d7b8-48c2-cf46-45045040945f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n,counts = 0,torch.zeros(len(vocab))\n",
        "for x,y in dls.valid:\n",
        "    n += y.shape[0]\n",
        "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
        "idx = torch.argmax(counts)\n",
        "idx, vocab[idx.item()], counts[idx].item()/n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(29), 'thousand', 0.15165200855716662)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56CNkwCgZhXi",
        "colab_type": "text"
      },
      "source": [
        "### Our first recurrent neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qckVsxEQZhXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jB7cr2ZZhXn",
        "colab_type": "code",
        "outputId": "ae5dbe08-bca3-4f24-ed8a-1847dc16812c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.816274</td>\n",
              "      <td>1.964143</td>\n",
              "      <td>0.460185</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.423805</td>\n",
              "      <td>1.739964</td>\n",
              "      <td>0.473259</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.430327</td>\n",
              "      <td>1.685172</td>\n",
              "      <td>0.485382</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.388390</td>\n",
              "      <td>1.657033</td>\n",
              "      <td>0.470406</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyc66aajZhXs",
        "colab_type": "text"
      },
      "source": [
        "## Improving the RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdqVyI-SZhXs",
        "colab_type": "text"
      },
      "source": [
        "### Maintaining the state of an RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXiyk2pSZhXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel3(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(3):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "        out = self.h_o(self.h)\n",
        "        self.h = self.h.detach()\n",
        "        return out\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TpOcq9nZhXw",
        "colab_type": "code",
        "outputId": "4f5c3e01-40da-402e-d2f4-4355c2be89b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m = len(seqs)//bs\n",
        "m,bs,len(seqs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(328, 64, 21031)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ue9vuOZhX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def group_chunks(ds, bs):\n",
        "    m = len(ds) // bs\n",
        "    new_ds = L()\n",
        "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
        "    return new_ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcSfG4LLZhX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs), \n",
        "    group_chunks(seqs[cut:], bs), \n",
        "    bs=bs, drop_last=True, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntcaVQIsZhYI",
        "colab_type": "code",
        "outputId": "1d1c4b7c-06ae-4ab1-e275-f655eeabc6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy,\n",
        "                metrics=accuracy, cbs=ModelReseter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.677074</td>\n",
              "      <td>1.827367</td>\n",
              "      <td>0.467548</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.282722</td>\n",
              "      <td>1.870913</td>\n",
              "      <td>0.388942</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.090705</td>\n",
              "      <td>1.651794</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.020034</td>\n",
              "      <td>1.698279</td>\n",
              "      <td>0.517788</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.976984</td>\n",
              "      <td>1.590866</td>\n",
              "      <td>0.538942</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.917347</td>\n",
              "      <td>1.626494</td>\n",
              "      <td>0.561298</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.889181</td>\n",
              "      <td>1.528347</td>\n",
              "      <td>0.574519</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.851054</td>\n",
              "      <td>1.771480</td>\n",
              "      <td>0.572115</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.802583</td>\n",
              "      <td>1.745915</td>\n",
              "      <td>0.583413</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.787742</td>\n",
              "      <td>1.744088</td>\n",
              "      <td>0.581250</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLKirgVOZhYP",
        "colab_type": "text"
      },
      "source": [
        "### Creating more signal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z-yfqbyZhYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sl = 16\n",
        "seqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
        "         for i in range(0,len(nums)-sl-1,sl))\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
        "                             group_chunks(seqs[cut:], bs),\n",
        "                             bs=bs, drop_last=True, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTEP67leZhYW",
        "colab_type": "code",
        "outputId": "719365bf-6c0b-47ed-9ab9-ef9789a2d9d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "[L(vocab[o] for o in s) for s in seqs[0]]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybMX-MhXZhYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel4(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for i in range(sl):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "            outs.append(self.h_o(self.h))\n",
        "        self.h = self.h.detach()\n",
        "        return torch.stack(outs, dim=1)\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G0gNr4MZhYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func(inp, targ):\n",
        "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq-YPT5vZhYg",
        "colab_type": "code",
        "outputId": "3e311c71-015b-40b0-9d83-6a987e6332c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelReseter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.285931</td>\n",
              "      <td>3.072032</td>\n",
              "      <td>0.212565</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.330371</td>\n",
              "      <td>1.969522</td>\n",
              "      <td>0.425781</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.742317</td>\n",
              "      <td>1.841378</td>\n",
              "      <td>0.441488</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.470120</td>\n",
              "      <td>1.810856</td>\n",
              "      <td>0.494303</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.298810</td>\n",
              "      <td>1.823128</td>\n",
              "      <td>0.492839</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.176835</td>\n",
              "      <td>1.755077</td>\n",
              "      <td>0.509440</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.071439</td>\n",
              "      <td>1.670006</td>\n",
              "      <td>0.519450</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.974427</td>\n",
              "      <td>1.821870</td>\n",
              "      <td>0.512858</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.897297</td>\n",
              "      <td>1.778148</td>\n",
              "      <td>0.554606</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.826408</td>\n",
              "      <td>1.609652</td>\n",
              "      <td>0.578532</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.776994</td>\n",
              "      <td>1.710498</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.737087</td>\n",
              "      <td>1.710610</td>\n",
              "      <td>0.591064</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.706825</td>\n",
              "      <td>1.794938</td>\n",
              "      <td>0.598226</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.688541</td>\n",
              "      <td>1.820462</td>\n",
              "      <td>0.592692</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.674543</td>\n",
              "      <td>1.783740</td>\n",
              "      <td>0.605794</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUXvSeWFZhYk",
        "colab_type": "text"
      },
      "source": [
        "## Multilayer RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSYbfDV4ZhYl",
        "colab_type": "text"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lXqwXONZhYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel5(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): self.h.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlRKQlOgZhYq",
        "colab_type": "code",
        "outputId": "29b453fb-bb2c-4874-ad96-0a098f89a920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "learn = Learner(dls, LMModel5(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelReseter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.041790</td>\n",
              "      <td>2.548714</td>\n",
              "      <td>0.455811</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.128514</td>\n",
              "      <td>1.708763</td>\n",
              "      <td>0.471029</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.699163</td>\n",
              "      <td>1.866050</td>\n",
              "      <td>0.340576</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.499681</td>\n",
              "      <td>1.738478</td>\n",
              "      <td>0.471517</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.339090</td>\n",
              "      <td>1.729538</td>\n",
              "      <td>0.494792</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.206317</td>\n",
              "      <td>1.835855</td>\n",
              "      <td>0.502848</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.088242</td>\n",
              "      <td>1.845557</td>\n",
              "      <td>0.520101</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.982788</td>\n",
              "      <td>1.856259</td>\n",
              "      <td>0.522624</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.890794</td>\n",
              "      <td>1.940332</td>\n",
              "      <td>0.525716</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.809587</td>\n",
              "      <td>2.028802</td>\n",
              "      <td>0.529785</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.743085</td>\n",
              "      <td>2.074602</td>\n",
              "      <td>0.535075</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.694128</td>\n",
              "      <td>2.153414</td>\n",
              "      <td>0.540039</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.660762</td>\n",
              "      <td>2.137611</td>\n",
              "      <td>0.547689</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.640680</td>\n",
              "      <td>2.169352</td>\n",
              "      <td>0.547363</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.630333</td>\n",
              "      <td>2.168203</td>\n",
              "      <td>0.548828</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I68MmAWnZhYs",
        "colab_type": "text"
      },
      "source": [
        "### Exploding or disappearing activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceLnH9kzZhYt",
        "colab_type": "text"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJLkyQxYZhYt",
        "colab_type": "text"
      },
      "source": [
        "### Building an LSTM from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiVSlMFzZhYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
        "        self.input_gate  = nn.Linear(ni + nh, nh)\n",
        "        self.cell_gate   = nn.Linear(ni + nh, nh)\n",
        "        self.output_gate = nn.Linear(ni + nh, nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        h = torch.stack([h, input], dim=1)\n",
        "        forget = torch.sigmoid(self.forget_gate(h))\n",
        "        c = c * forget\n",
        "        inp = torch.sigmoid(self.input_gate(h))\n",
        "        cell = torch.tanh(self.cell_gate(h))\n",
        "        c = c + inp * cell\n",
        "        out = torch.sigmoid(self.output_gate(h))\n",
        "        h = outgate * torch.tanh(c)\n",
        "        return h, (h,c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIR35ItyZhYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.ih = nn.Linear(ni,4*nh)\n",
        "        self.hh = nn.Linear(nh,4*nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        #One big multiplication for all the gates is better than 4 smaller ones\n",
        "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1)\n",
        "        ingate,forgetgate,outgate = map(torch.sigmoid, gates[:3])\n",
        "        cellgate = gates[3].tanh()\n",
        "\n",
        "        c = (forgetgate*c) + (ingate*cellgate)\n",
        "        h = outgate * c.tanh()\n",
        "        return h, (h,c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WvUZ5R1ZhY1",
        "colab_type": "code",
        "outputId": "61d7dd58-9fbb-4c3c-df41-b662be037c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = torch.arange(0,10); t"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEEfdfrkZhY8",
        "colab_type": "code",
        "outputId": "a79e735c-3d53-424a-9bda-d6da766a9c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.chunk(2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4]), tensor([5, 6, 7, 8, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7617DLhYZhZA",
        "colab_type": "text"
      },
      "source": [
        "### Training a language model using LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES69HsIOZhZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel6(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xpboXYhZhZH",
        "colab_type": "code",
        "outputId": "6e53570f-26fe-4669-e6eb-c0d5efc04c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "learn = Learner(dls, LMModel6(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelReseter)\n",
        "learn.fit_one_cycle(15, 1e-2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.026113</td>\n",
              "      <td>2.772102</td>\n",
              "      <td>0.153076</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.216184</td>\n",
              "      <td>2.089064</td>\n",
              "      <td>0.269124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.613939</td>\n",
              "      <td>1.826132</td>\n",
              "      <td>0.478760</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.315355</td>\n",
              "      <td>2.057055</td>\n",
              "      <td>0.504395</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.084344</td>\n",
              "      <td>2.010173</td>\n",
              "      <td>0.605957</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.857388</td>\n",
              "      <td>1.925331</td>\n",
              "      <td>0.613688</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.621264</td>\n",
              "      <td>2.082762</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.410109</td>\n",
              "      <td>1.927088</td>\n",
              "      <td>0.731852</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.261468</td>\n",
              "      <td>1.890257</td>\n",
              "      <td>0.771891</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.153808</td>\n",
              "      <td>1.779679</td>\n",
              "      <td>0.776530</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.093393</td>\n",
              "      <td>1.771678</td>\n",
              "      <td>0.791260</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.060462</td>\n",
              "      <td>1.745478</td>\n",
              "      <td>0.790283</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.042987</td>\n",
              "      <td>1.746838</td>\n",
              "      <td>0.784261</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.034032</td>\n",
              "      <td>1.740035</td>\n",
              "      <td>0.785970</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.029984</td>\n",
              "      <td>1.748533</td>\n",
              "      <td>0.783936</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJU1-yT2ZhZN",
        "colab_type": "text"
      },
      "source": [
        "## Regularizing an LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmtWUbsyZhZN",
        "colab_type": "text"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQWY9wEjZhZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dropout(Module):\n",
        "    def __init__(self, p): self.p = p\n",
        "    def forward(self, x):\n",
        "        if not self.training: return x\n",
        "        mask = x.new(*x.shape).bernoulli_(1-p)\n",
        "        return x * mask.div_(1-p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlNH0WNIZhZT",
        "colab_type": "text"
      },
      "source": [
        "### AR and TAR regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-MUf9zXZhZV",
        "colab_type": "text"
      },
      "source": [
        "### Training a weight-tied regularized LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS6n_oZ_ZhZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel7(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        raw,h = self.rnn(self.i_h(x), self.h)\n",
        "        out = self.drop(raw)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(out),raw,out\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sAfhvb4ZhZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(dls, LMModel7(len(vocab), 64, 2, 0.5),\n",
        "                loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "                cbs=[ModelReseter, RNNRegularizer(alpha=2, beta=1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OntNYagZhZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
        "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGwIvRoGZhZh",
        "colab_type": "code",
        "outputId": "5194d695-57ec-47fa-d893-2a3b61ffde6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.491892</td>\n",
              "      <td>1.932190</td>\n",
              "      <td>0.512288</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.591766</td>\n",
              "      <td>1.156544</td>\n",
              "      <td>0.644287</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.912455</td>\n",
              "      <td>0.704682</td>\n",
              "      <td>0.785807</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.539008</td>\n",
              "      <td>0.689723</td>\n",
              "      <td>0.796387</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.365301</td>\n",
              "      <td>0.531083</td>\n",
              "      <td>0.840658</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.255372</td>\n",
              "      <td>0.517299</td>\n",
              "      <td>0.843587</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.202067</td>\n",
              "      <td>0.422006</td>\n",
              "      <td>0.871419</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.170186</td>\n",
              "      <td>0.422818</td>\n",
              "      <td>0.876546</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.148469</td>\n",
              "      <td>0.441053</td>\n",
              "      <td>0.866618</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.136168</td>\n",
              "      <td>0.428971</td>\n",
              "      <td>0.872721</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.125081</td>\n",
              "      <td>0.402029</td>\n",
              "      <td>0.881917</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.116374</td>\n",
              "      <td>0.386480</td>\n",
              "      <td>0.881429</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.110173</td>\n",
              "      <td>0.390175</td>\n",
              "      <td>0.883708</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.105375</td>\n",
              "      <td>0.392710</td>\n",
              "      <td>0.882568</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.103071</td>\n",
              "      <td>0.389780</td>\n",
              "      <td>0.884440</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flpPSIpTZhZt",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DnDG3EsZhZw",
        "colab_type": "text"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vHn6C5tZhZw",
        "colab_type": "text"
      },
      "source": [
        "1. If the dataset for your project is so big and complicated that working with it takes a significant amount of time, what should you do?\n",
        "1. Why do we concatenate the documents in our dataset before creating a language model?\n",
        "1. To use a standard fully connected network to predict the fourth word given the previous three words, what two tweaks do we need to make?\n",
        "1. How can we share a weight matrix across multiple layers in PyTorch?\n",
        "1. Write a module which predicts the third word given the previous two words of a sentence, without peeking.\n",
        "1. What is a recurrent neural network?\n",
        "1. What is hidden state?\n",
        "1. What is the equivalent of hidden state in ` LMModel1`?\n",
        "1. To maintain the state in an RNN why is it important to pass the text to the model in order?\n",
        "1. What is an unrolled representation of an RNN?\n",
        "1. Why can maintaining the hidden state in an RNN lead to memory and performance problems? How do we fix this problem?\n",
        "1. What is BPTT?\n",
        "1. Write code to print out the first few batches of the validation set, including converting the token IDs back into English strings, as we showed for batches of IMDb data in <<chapter_nlp>>.\n",
        "1. What does the `ModelReseter` callback do? Why do we need it?\n",
        "1. What are the downsides of predicting just one output word for each three input words?\n",
        "1. Why do we need a custom loss function for `LMModel4`?\n",
        "1. Why is the training of `LMModel4` unstable?\n",
        "1. In the unrolled representation, we can see that a recurrent neural network actually has many layers. So why do we need to stack RNNs to get better results?\n",
        "1. Draw a representation of a stacked (multilayer) RNN.\n",
        "1. Why should we get better results in an RNN if we call `detach` less often? Why might this not happen in practice with a simple RNN?\n",
        "1. Why can a deep network result in very large or very small activations? Why does this matter?\n",
        "1. In a computer's floating point representation of numbers, which numbers are the most precise?\n",
        "1. Why do vanishing gradients prevent training?\n",
        "1. Why does it help to have two hidden states in the LSTM architecture? What is the purpose of each one?\n",
        "1. What are these two states called in an LSTM?\n",
        "1. What is tanh, and how is it related to sigmoid?\n",
        "1. What is the purpose of this code in `LSTMCell`?: `h = torch.stack([h, input], dim=1)`\n",
        "1. What does `chunk` to in PyTorch?\n",
        "1. Study the refactored version of `LSTMCell` carefully to ensure you understand how and why it does the same thing as the non-refactored version.\n",
        "1. Why can we use a higher learning rate for `LMModel6`?\n",
        "1. What are the three regularisation techniques used in an AWD-LSTM model?\n",
        "1. What is dropout?\n",
        "1. Why do we scale the weights with dropout? Is this applied during training, inference, or both?\n",
        "1. What is the purpose of this line from `Dropout`?: `if not self.training: return x`\n",
        "1. Experiment with `bernoulli_` to understand how it works.\n",
        "1. How do you set your model in training mode in PyTorch? In evaluation mode?\n",
        "1. Write the equation for activation regularization (in maths or code, as you prefer). How is it different to weight decay?\n",
        "1. Write the equation for temporal activation regularization (in maths or code, as you prefer). Why wouldn't we use this for computer vision problems?\n",
        "1. What is \"weight tying\" in a language model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6hUnuY7ZhZx",
        "colab_type": "text"
      },
      "source": [
        "### Further research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XfHHnUqZhZy",
        "colab_type": "text"
      },
      "source": [
        "1. In ` LMModel2` why can `forward` start with `h=0`? Why don't we need to say `h=torch.zeros(…)`?\n",
        "1. Write the code for an LSTM from scratch (but you may refer to <<lstm>>).\n",
        "1. Search on the Internet for the GRU architecture and implement it from scratch, and try training a model. See if you can get the similar results as we saw in this chapter. Compare it to the results of PyTorch's built in GRU module.\n",
        "1. Have a look at the source code for AWD-LSTM in fastai, and try to map each of the lines of code to the concepts shown in this chapter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1RumyBaZhZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}